{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis of City Bikes in the Bay Area\n",
    "\n",
    "* http://www.bayareabikeshare.com\n",
    "* https://www.fordgobike.com/system-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "import dill as pickle\n",
    "\n",
    "\n",
    "\n",
    "## homemade\n",
    "import fetchData as fd\n",
    "import exploratoryAnalysis as expAn\n",
    "import distanceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \\n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stationName = 'San Francisco Caltrain (Townsend at 4th)'  \n",
    "#stationName = 'Market at Sansome' \n",
    "\n",
    "freq_hour = 1  ## sampling frequency to cumulate the nb. of bike trips\n",
    " \n",
    "paths = [r'../data/babs_open_data_year_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, Read and Clean raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p ../data\n",
    "directory = \"../data/\"\n",
    "\n",
    "links = [\"https://s3.amazonaws.com/babs-open-data/babs_open_data_year_1.zip\",\n",
    "         \"https://s3.amazonaws.com/babs-open-data/babs_open_data_year_2.zip\",\n",
    "         \"https://s3.amazonaws.com/babs-open-data/babs_open_data_year_3.zip\"]\n",
    "for url in links:\n",
    "    (filename, path_to_file) = fd.download_file_by_url(url, directory)\n",
    "    fd.unzip_file(filename, path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/babs_open_data_year_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure we get the time from the right timezone \n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "#print pytz.all_timezones\n",
    "parse = lambda x: pytz.timezone('US/Pacific').localize(datetime.strptime(x,'%m/%d/%Y %H:%M')) #.astimezone(pytz.timezone('US/Pacific'))\n",
    "print(parse(\"8/31/2015 23:26\").astimezone(pytz.timezone('Europe/Paris')))\n",
    "\n",
    "print(\"Now in Oslo (Norway): \", pytz.timezone('Europe/Oslo').localize(datetime.now()))\n",
    "print(\"Now in San Francisco: \", pytz.timezone('Europe/Oslo').localize(datetime.now()).astimezone(pytz.timezone('America/Los_Angeles')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trips data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BikeTrips data (takes a few minutes!!)\n",
    "dataTrips = expAn.read_or_store_object('dataTrips', './pkl', expAn.read_dataTrips_from_csv_files, paths=paths, asUTC=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUPPLY & DEMAND: Count how many bikes are arriving/leaving per x hour at a given station\n",
    "cumulEndTrips   = expAn.read_or_store_object('cumulEndTrips', './pkl',\n",
    "                                             expAn.count_bikes_arriving, dataTrips, stationName, freq_hour)\n",
    "cumulStartTrips = expAn.read_or_store_object('cumulStartTrips', './pkl',\n",
    "                                             expAn.count_bikes_leaving, dataTrips, stationName, freq_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrips.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationData  = expAn.read_dataStation_from_csv_files(paths)\n",
    "stationID    = expAn.get_stationID(stationName, stationData)\n",
    "stationDockcount = expAn.get_stationDockcount(stationName, stationData)\n",
    "(lat, lon)    = expAn.get_station_coordinates(stationName, stationData)\n",
    "neighboursIDs = expAn.get_neighbouring_stationIDs(stationData, stationName, radius=.65)\n",
    "print(\"IDs of neighbouring stations to {statName}: {IDs}\".format(statName=stationName, IDs=neighboursIDs))\n",
    "print(\"Names stations nearby {statName}:\\n{Names}\".format(statName=stationName,\n",
    "                                                                   Names=expAn.get_stationNames(neighboursIDs, stationData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationNames = list(stationData[\"name\"].unique()) \n",
    "freq = \"1\"\n",
    "#for stationName in stationNames:\n",
    "#    cumulEndTrips   = expAn.count_bikes_arriving(dataTrips, stationName, freq)\n",
    "cumulEndTrips   = expAn.count_bikes_arriving(dataTrips, stationNames[0], freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateparse = lambda x: pytz.timezone('US/Pacific').localize(datetime.strptime(x,'%m/%d/%Y')).astimezone(timezone('UTC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse('9/1/2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/babs_open_data_year_2/201508_weather_data.csv', index_col=0, date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherData = expAn.read_dataWeather_from_csv_files(paths=paths)\n",
    "print(\"postal codes available with weather forecast: \", weatherData['Zip'].unique())\n",
    "(precipitation_mm, temperature_celcius) = expAn.get_weatherInfos(weatherData, stationData, stationName)\n",
    "weatherInfos = {}\n",
    "weatherInfos['precipitation_mm']    = precipitation_mm\n",
    "weatherInfos['temperature_celcius'] = temperature_celcius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for a given station:\n",
    "\n",
    "* Build a prediction model for the **supply** and **demand** of bikes which takes into account:\n",
    "    * earlier samples,\n",
    "    * the weather data,\n",
    "    * possibly information about neighbour stations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the number of bikes arriving, and compare various algorithms\n",
    "\n",
    "* linear regression\n",
    "* decision tree regressor\n",
    "* Random Forest\n",
    "* Boosted decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputsDemand = [{'title':'Prediction of bike demand from {stationName}'.format(stationName=stationName),\n",
    "                 'data':cumulStartTrips,\n",
    "                 'freq_hour':freq_hour, 'supply_demand':'demand', 'checkDockAvailable':False,\n",
    "                 'withWeather':True,\n",
    "                 'label':'Linear Regression', 'algo':'LinearRegression',\n",
    "                 'ratioTest':0.3, },\n",
    "#                 {\n",
    "#                  'title':'Prediction of bike demand from {stationName}'.format(stationName=stationName),\n",
    "#                  'data' : cumulStartTrips, \n",
    "#                  'freq_hour':freq_hour, 'supply_demand':'demand', 'checkDockAvailable':False,\n",
    "#                  'withWeather':True,\n",
    "#                  'label':'Random Forest', 'algo':'RandomForestRegressor',\n",
    "#                  'ratioTest':0.3, \n",
    "#                  },\n",
    "                ]\n",
    "\n",
    "                \n",
    "#                 {'name':'Linear Regression (no weather)', 'algo':'LinearRegression', \n",
    "#           'ratioTest':0.3, 'predictFromPast':True, 'withWeather':False, 'checkDockAvailable':True},\n",
    "          \n",
    "#           {'name':'Linear Regression with weather infos ', 'algo':'LinearRegression', \n",
    "#           'ratioTest':0.3, 'predictFromPast':True, 'withWeather':True, 'checkDockAvailable':True},\n",
    "          \n",
    "#           {'name':'Decision Tree', 'algo':'DecisionTreeRegressor',\n",
    "#           'ratioTest':0.3, 'predictFromPast':True, 'withWeather':True, 'checkDockAvailable':True},\n",
    "        \n",
    "          \n",
    "#          {'name':'Boosted Decision Tree', 'algo':'BoostedDecisionTreeRegressor',\n",
    "#           'ratioTest':0.3, 'predictFromPast':True, 'withWeather':True, 'checkDockAvailable':True},\n",
    "          \n",
    "#          {'name':'Gradient Boosting Regressor', 'algo':'GradientBoostingRegressor',\n",
    "#           'ratioTest':0.3, 'predictFromPast':True, 'withWeather':True, 'checkDockAvailable':True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputsSupply = [{\n",
    "                 'title':'Prediction of bike supply @ {stationName}'.format(stationName=stationName),\n",
    "                 'data' : cumulEndTrips, \n",
    "                 'freq_hour':freq_hour, 'supply_demand':'supply', 'checkDockAvailable':True,\n",
    "                 'withWeather': True,\n",
    "                 'label':'Linear Regression', 'algo':'LinearRegression',\n",
    "                 'ratioTest':0.3,\n",
    "                 },\n",
    "#                 {\n",
    "#                  'title':'Prediction of bike supply @ {stationName}'.format(stationName=stationName),\n",
    "#                  'data' : cumulEndTrips, \n",
    "#                  'freq_hour':freq_hour, 'supply_demand':'supply', 'checkDockAvailable':True,\n",
    "#                  'withWeather': True,\n",
    "#                  'label':'Random Forest', 'algo':'RandomForestRegressor',\n",
    "#                  'ratioTest':0.3, \n",
    "#                  },\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offsetsTrip = [pd.DateOffset(**k) for k in [{'hours': 1*freq_hour},{'hours': 2*freq_hour},\\\n",
    "                                            {'hours': 3*freq_hour}, {'hours': 8*freq_hour},\\\n",
    "                                            {'days': 1}, {'days': 7}, {'days': 14},\\\n",
    "                                            {'days': 28}]]\n",
    "# weatherInfos['precipitation_mm'].index.asof(str(date(2013,8,29)))\n",
    "print date(2013,8,29)\n",
    "earliestTime =  date(2013,8,29) + offsetsTrip[-1]\n",
    "print \"earliestTime: \",earliestTime\n",
    "print [earliestTime-i for i in offsetsTrip]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_full, y_full) = expAn.build_model_inputs(inputsSupply[0], weatherInfos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_split_train_predict(inputs, weatherInfos={}):\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "    outputs = []\n",
    "    for inp in inputs:\n",
    "        ## READ AND COMPLETE INPUTS WITH DEFAULT VALUES IF MISSING\n",
    "        inpDF = inp['data']\n",
    "        output = inp\n",
    "        if 'algo' not in inp.keys():\n",
    "            output['algo'] = 'LinearRegression'\n",
    "        if 'ratioTest' not in inp.keys():\n",
    "            output['ratioTest'] = 0.3\n",
    "        if 'withWeather' not in inp.keys():\n",
    "            output['withWeather'] = True\n",
    "        if 'checkDockAvailable' not in inp.keys():\n",
    "            output['checkDockAvailable'] = True\n",
    "        if 'checkBikeAvailable' not in inp.keys():\n",
    "            output['checkBikeAvailable'] = True\n",
    "        ## build the model\n",
    "        (X_full, y_full) = expAn.build_model_inputs(inp, weatherInfos)\n",
    "\n",
    "        # Split the data into training/testing sets\n",
    "        nTest = int(round(len(X_full)*output['ratioTest']))\n",
    "        X_trainingSet = X_full[:-nTest]\n",
    "        X_testingSet  = X_full[-nTest:]\n",
    "        # Split the targets into training/testing sets\n",
    "        y_train = y_full[:-nTest]\n",
    "        y_test  = y_full[-nTest:]\n",
    "        output['X_full'] = X_full\n",
    "        output['y_full'] = y_full\n",
    "        output['X_trainingSet'] = X_trainingSet\n",
    "        output['X_testingSet'] = X_testingSet\n",
    "        output['y_train'] = y_train\n",
    "        output['y_test'] = y_test\n",
    "        output['dates_train'] = inpDF.index[:-nTest]\n",
    "        output['dates_test'] = inpDF.index[-nTest:]\n",
    "        print inp['algo']\n",
    "\n",
    "        ## Normalizing the model coefficients for meaningful comparison\n",
    "        ## Standardization, or mean removal and variance scaling\n",
    "        ## (http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n",
    "        scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit(X_trainingSet)\n",
    "        X_trainingSet = scaler.transform(X_trainingSet)\n",
    "        X_testingSet = scaler.transform(X_testingSet)\n",
    "        \n",
    "        # Train the model using the training sets\n",
    "        print '\\nLabel: {}'.format(output['label'])\n",
    "        \n",
    "#         algo = {'LinearRegression':LinearRegression(),\n",
    "#                 'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "#                 'RandomForestRegressor':RandomForestRegressor(n_estimators=150, min_samples_split=1),\n",
    "#                 'BoostedDecisionTreeRegressor':AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "#                                                                  n_estimators=150).fit(X_trainingSet, y_train),\n",
    "#                 'GradientBoostingRegressor':GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
    "#                                                                       max_depth=3, max_features=None,\n",
    "#                                                                       min_samples_leaf=1, min_samples_split=2,\n",
    "#                                                                       n_estimators=100,\n",
    "#                                                                       random_state=None, subsample=1.0, verbose=0)}[inp['algo']]\n",
    "\n",
    "\n",
    "        algo = {'LinearRegression':LinearRegression()}[inp['algo']]        \n",
    "        model = algo.fit(X_trainingSet, y_train)\n",
    "        output['model'] = model\n",
    "        \n",
    "        RSS = sum((y_train - model.predict(X_trainingSet))**2)  ## residual sum of squares (RSS) p.62\n",
    "        TSS = sum((y_train - np.mean(y_train))**2)\n",
    "        \n",
    "        ## The residual standard error (RSE) provides an absolute measure of lack of fit of the model to the data.\n",
    "        RSE = (RSS/(len(y_train)-2))**(0.5) ## residual standard error (RSE) p.69\n",
    "        \n",
    "        ## But since the RSE is measured in the units of Y , it is not always clear what constitutes a good RSE.\n",
    "        ## The R**2 statistic provides an alternative measure of fit. It takes the form of a proportion\n",
    "        ## — the proportion of variance explained — and so it always takes on a value between 0 and 1, and is \n",
    "        ## independent of the scale of Y. (p.69-70)\n",
    "        R2statistic = 1. - RSS/TSS\n",
    "        \n",
    "        # prediction\n",
    "        y_predict = model.predict(X_testingSet) # to compare to the real values: y_test\n",
    "        output['y_predict'] = y_predict\n",
    "\n",
    "        ### Explained variance score: 1 is perfect prediction\n",
    "        #if inp['algo'] != 'RandomForestRegressor':\n",
    "        scoreVarTrain = model.score(X_trainingSet, y_train)\n",
    "        scoreVarTest = model.score(X_testingSet, y_test)\n",
    "        sse = np.mean((y_predict - y_test) ** 2)\n",
    "        print(\"sum of squared errors of prediction (SSE): %.2f\" % sse)\n",
    "        print('Variance score on training set: %.2f' % scoreVarTrain)\n",
    "        print('Variance score on test set: %.2f' % scoreVarTest)\n",
    "        print('RSE: %.2f' % RSE)\n",
    "        print('R^2: %.2f' % R2statistic)\n",
    "        stats = {'scoreVarTrain':scoreVarTrain,\n",
    "                 'scoreVarTest':scoreVarTest, 'sse':sse,\n",
    "                 'RSS':RSS, 'TSS':TSS, 'RSE':RSE,\n",
    "                 'R2statistic':R2statistic}\n",
    "        output['stats'] = stats\n",
    "        outputs.append(output)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_supply = build_split_train_predict(inputsSupply, weatherInfos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_demand = build_split_train_predict(inputsDemand, weatherInfos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot to compare the combinations of input parameters and AI algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_prediction(outputs, title=\"\", weatherInfos={}):\n",
    "    timeUTC = outputs[0]['dates_test'].tolist()\n",
    "    timePST = [pytz.timezone('UTC').localize(x).astimezone(timezone('US/Pacific')) for x in timeUTC]\n",
    "    actual_data = outputs[0]['y_test']\n",
    "    temper = [weatherInfos['temperature_celcius'][weatherInfos['temperature_celcius'].index.asof(i)] for i in outputs[0]['data'].index]\n",
    "    precip = [weatherInfos['precipitation_mm'][weatherInfos['precipitation_mm'].index.asof(i)] for i in outputs[0]['data'].index]\n",
    "    \n",
    "    p = figure(title=\"Predictions\", #toolbar_location=None,\n",
    "               plot_width=800, plot_height=600, x_axis_type='datetime')\n",
    "    #p.grid.grid_line_color = None\n",
    "    p.background_fill_color = \"#eeeeee\"\n",
    "    for output in outputs:\n",
    "        p.line(timePST, np.array(output['y_predict']),\n",
    "               line_width=2, line_color=\"red\",\n",
    "               legend=output['label'])\n",
    "#     p.line(timePST, temper, line_width=2, legend='Temp. (C)')\n",
    "#     p.line(timePST, precip, line_width=2, legend='Rain (mm)')\n",
    "    p.line(timePST, actual_data, line_width=2, line_color=\"gray\", legend='Actual')\n",
    "    p.xaxis.axis_label = 'Time'\n",
    "    p.yaxis.axis_label = 'Bikes'\n",
    "    output_file(\"predictions.html\", title=\"Bay Area citybikes\")\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_prediction(results_supply,\n",
    "                title='cityBikes/Prediction of bike supply @ {stationName}'.format(stationName=stationName),\n",
    "                weatherInfos=weatherInfos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
